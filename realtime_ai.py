#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ AI ì—ì´ì „íŠ¸
- í•­ìƒ ë§ˆì´í¬ ì²­ì·¨
- ë„êµ¬ ì‹¤í–‰
- ìê°€ í•™ìŠµ/ê°œì„ 
- GTX 1050 Ti 4GB ìµœì í™”
"""

import os
import sys
import json
import time
import queue
import threading
import subprocess
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List, Any, Callable
from dataclasses import dataclass, field
import warnings

warnings.filterwarnings("ignore")

# ì„¤ì •
MODEL_NAME = "qwen2.5:3b"  # 1.9GB - GTX 1050 Tiì— ì í•©
OLLAMA_URL = "http://localhost:11434"
MEMORY_FILE = "/mnt/data/HyperCLOVAX-AGI/ai_memory.json"
LEARNING_FILE = "/mnt/data/HyperCLOVAX-AGI/ai_learnings.json"


@dataclass
class AIMemory:
    """AI ë©”ëª¨ë¦¬ (ìê°€ ìˆ˜ì • ê°€ëŠ¥)"""
    short_term: List[Dict] = field(default_factory=list)  # ìµœê·¼ ëŒ€í™”
    long_term: Dict[str, Any] = field(default_factory=dict)  # ì˜êµ¬ ì§€ì‹
    learnings: List[Dict] = field(default_factory=list)  # í•™ìŠµ ë‚´ìš©
    preferences: Dict[str, Any] = field(default_factory=dict)  # ì‚¬ìš©ì ì„ í˜¸

    def save(self):
        """ë©”ëª¨ë¦¬ ì €ì¥"""
        data = {
            "short_term": self.short_term[-20:],  # ìµœê·¼ 20ê°œë§Œ
            "long_term": self.long_term,
            "learnings": self.learnings[-100:],  # ìµœê·¼ 100ê°œ
            "preferences": self.preferences,
            "last_updated": datetime.now().isoformat(),
        }
        with open(MEMORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def load(self):
        """ë©”ëª¨ë¦¬ ë¡œë“œ"""
        if os.path.exists(MEMORY_FILE):
            try:
                with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                self.short_term = data.get("short_term", [])
                self.long_term = data.get("long_term", {})
                self.learnings = data.get("learnings", [])
                self.preferences = data.get("preferences", {})
                print(f"ğŸ“š ë©”ëª¨ë¦¬ ë¡œë“œ: {len(self.learnings)}ê°œ í•™ìŠµ ë‚´ìš©")
            except:
                pass

    def add_learning(self, category: str, content: str, source: str = "conversation"):
        """í•™ìŠµ ë‚´ìš© ì¶”ê°€"""
        self.learnings.append({
            "category": category,
            "content": content,
            "source": source,
            "timestamp": datetime.now().isoformat(),
        })
        self.save()

    def add_conversation(self, role: str, content: str):
        """ëŒ€í™” ì¶”ê°€"""
        self.short_term.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
        })
        if len(self.short_term) > 20:
            self.short_term = self.short_term[-20:]


class ToolExecutor:
    """ë„êµ¬ ì‹¤í–‰ê¸°"""

    def __init__(self):
        self.tools = {
            "bash": self.run_bash,
            "python": self.run_python,
            "search": self.web_search,
            "read_file": self.read_file,
            "write_file": self.write_file,
            "list_files": self.list_files,
            "system_info": self.system_info,
            "time": self.get_time,
            "calculator": self.calculator,
        }

    def run_bash(self, command: str) -> str:
        """Bash ëª…ë ¹ ì‹¤í–‰"""
        try:
            result = subprocess.run(
                command, shell=True,
                capture_output=True, text=True,
                timeout=30
            )
            output = result.stdout + result.stderr
            return output[:2000] if output else "[ì™„ë£Œ]"
        except subprocess.TimeoutExpired:
            return "[íƒ€ì„ì•„ì›ƒ]"
        except Exception as e:
            return f"[ì˜¤ë¥˜: {e}]"

    def run_python(self, code: str) -> str:
        """Python ì½”ë“œ ì‹¤í–‰"""
        try:
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(code)
                temp_path = f.name

            result = subprocess.run(
                ['python3', temp_path],
                capture_output=True, text=True,
                timeout=30
            )
            os.unlink(temp_path)
            output = result.stdout + result.stderr
            return output[:2000] if output else "[ì™„ë£Œ]"
        except Exception as e:
            return f"[ì˜¤ë¥˜: {e}]"

    def web_search(self, query: str) -> str:
        """ì›¹ ê²€ìƒ‰ (ì‹œë®¬ë ˆì´ì…˜)"""
        return f"[ì›¹ ê²€ìƒ‰ '{query}' - ì‹¤ì œ êµ¬í˜„ í•„ìš”]"

    def read_file(self, path: str) -> str:
        """íŒŒì¼ ì½ê¸°"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()
            return content[:3000]
        except Exception as e:
            return f"[ì˜¤ë¥˜: {e}]"

    def write_file(self, path: str, content: str) -> str:
        """íŒŒì¼ ì“°ê¸°"""
        try:
            with open(path, 'w', encoding='utf-8') as f:
                f.write(content)
            return f"[ì €ì¥ë¨: {path}]"
        except Exception as e:
            return f"[ì˜¤ë¥˜: {e}]"

    def list_files(self, path: str = ".") -> str:
        """íŒŒì¼ ëª©ë¡"""
        try:
            files = os.listdir(path)
            return "\n".join(files[:50])
        except Exception as e:
            return f"[ì˜¤ë¥˜: {e}]"

    def system_info(self) -> str:
        """ì‹œìŠ¤í…œ ì •ë³´"""
        try:
            import platform
            info = [
                f"OS: {platform.system()} {platform.release()}",
                f"Python: {platform.python_version()}",
                f"Machine: {platform.machine()}",
            ]

            # GPU ì •ë³´
            try:
                gpu = subprocess.run(
                    "nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader",
                    shell=True, capture_output=True, text=True
                )
                if gpu.stdout:
                    info.append(f"GPU: {gpu.stdout.strip()}")
            except:
                pass

            return "\n".join(info)
        except Exception as e:
            return f"[ì˜¤ë¥˜: {e}]"

    def get_time(self) -> str:
        """í˜„ì¬ ì‹œê°„"""
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def calculator(self, expression: str) -> str:
        """ê³„ì‚°ê¸°"""
        try:
            # ì•ˆì „í•œ ìˆ˜ì‹ë§Œ í—ˆìš©
            allowed = set("0123456789+-*/().% ")
            if not all(c in allowed for c in expression):
                return "[í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë¬¸ì]"
            result = eval(expression)
            return str(result)
        except Exception as e:
            return f"[ì˜¤ë¥˜: {e}]"

    def execute(self, tool_name: str, **kwargs) -> str:
        """ë„êµ¬ ì‹¤í–‰"""
        if tool_name not in self.tools:
            return f"[ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool_name}]"

        tool = self.tools[tool_name]
        try:
            # ì²« ë²ˆì§¸ ì¸ì ì¶”ì¶œ
            if kwargs:
                first_arg = list(kwargs.values())[0]
                return tool(first_arg) if len(kwargs) == 1 else tool(**kwargs)
            return tool()
        except Exception as e:
            return f"[ì‹¤í–‰ ì˜¤ë¥˜: {e}]"


class MicrophoneListener:
    """ë§ˆì´í¬ ì²­ì·¨ê¸°"""

    def __init__(self, callback: Callable[[str], None]):
        self.callback = callback
        self.running = False
        self.thread = None

        # ìŒì„± ì¸ì‹ í™•ì¸
        try:
            import speech_recognition as sr
            self.recognizer = sr.Recognizer()
            self.has_sr = True
            print("âœ… ìŒì„± ì¸ì‹ ì¤€ë¹„ë¨")
        except ImportError:
            self.has_sr = False
            print("âš ï¸ speech_recognition ë¯¸ì„¤ì¹˜ - í…ìŠ¤íŠ¸ ì…ë ¥ë§Œ ì‚¬ìš©")

    def start(self):
        """ì²­ì·¨ ì‹œì‘"""
        if not self.has_sr:
            return

        self.running = True
        self.thread = threading.Thread(target=self._listen_loop, daemon=True)
        self.thread.start()
        print("ğŸ¤ ë§ˆì´í¬ ì²­ì·¨ ì‹œì‘")

    def stop(self):
        """ì²­ì·¨ ì¤‘ì§€"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=2)

    def _listen_loop(self):
        """ì²­ì·¨ ë£¨í”„"""
        import speech_recognition as sr

        while self.running:
            try:
                with sr.Microphone() as source:
                    self.recognizer.adjust_for_ambient_noise(source, duration=0.3)
                    audio = self.recognizer.listen(source, timeout=5, phrase_time_limit=10)

                try:
                    text = self.recognizer.recognize_google(audio, language="ko-KR")
                    if text:
                        print(f"\nğŸ¤ ì¸ì‹: {text}")
                        self.callback(text)
                except sr.UnknownValueError:
                    pass
                except sr.RequestError:
                    pass

            except Exception:
                time.sleep(1)


class OllamaClient:
    """Ollama í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, model: str = MODEL_NAME):
        self.model = model
        self.base_url = OLLAMA_URL

    def generate(self, prompt: str, system: str = None, stream: bool = True) -> str:
        """í…ìŠ¤íŠ¸ ìƒì„±"""
        import requests

        data = {
            "model": self.model,
            "prompt": prompt,
            "stream": stream,
        }

        if system:
            data["system"] = system

        try:
            if stream:
                response = requests.post(
                    f"{self.base_url}/api/generate",
                    json=data,
                    stream=True,
                    timeout=60
                )

                full_response = ""
                for line in response.iter_lines():
                    if line:
                        chunk = json.loads(line)
                        if "response" in chunk:
                            text = chunk["response"]
                            print(text, end="", flush=True)
                            full_response += text
                        if chunk.get("done"):
                            break

                print()  # ì¤„ë°”ê¿ˆ
                return full_response
            else:
                response = requests.post(
                    f"{self.base_url}/api/generate",
                    json=data,
                    timeout=60
                )
                return response.json().get("response", "")

        except Exception as e:
            return f"[Ollama ì˜¤ë¥˜: {e}]"

    def is_available(self) -> bool:
        """Ollama ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        import requests
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False


class RealtimeAI:
    """ì‹¤ì‹œê°„ AI ì—ì´ì „íŠ¸"""

    def __init__(self):
        self.memory = AIMemory()
        self.memory.load()

        self.tools = ToolExecutor()
        self.ollama = OllamaClient()

        self.mic_listener = None
        self.input_queue = queue.Queue()
        self.running = False

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompt = """ë‹¹ì‹ ì€ ì‹¤ì‹œê°„ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

íŠ¹ì§•:
- í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”
- ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥ (bash, python, file ë“±)
- í•™ìŠµ ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ê°œì„ 

ë„êµ¬ ì‚¬ìš© í˜•ì‹:
[TOOL: tool_name](argument)

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
- bash: ì‰˜ ëª…ë ¹ ì‹¤í–‰
- python: íŒŒì´ì¬ ì½”ë“œ ì‹¤í–‰
- read_file: íŒŒì¼ ì½ê¸°
- write_file: íŒŒì¼ ì“°ê¸°
- list_files: íŒŒì¼ ëª©ë¡
- system_info: ì‹œìŠ¤í…œ ì •ë³´
- time: í˜„ì¬ ì‹œê°„
- calculator: ê³„ì‚°

í•™ìŠµ í˜•ì‹:
[LEARN: category](content)

ì˜ˆì‹œ:
"í˜„ì¬ ì‹œê°„ì€?" â†’ [TOOL: time]()
"3+5 ê³„ì‚°í•´ì¤˜" â†’ [TOOL: calculator](3+5)
"í™ˆ ë””ë ‰í† ë¦¬ íŒŒì¼ ë³´ì—¬ì¤˜" â†’ [TOOL: bash](ls ~)
"""

    def process_response(self, response: str) -> str:
        """ì‘ë‹µ ì²˜ë¦¬ (ë„êµ¬ ì‹¤í–‰, í•™ìŠµ ì €ì¥)"""
        import re

        # ë„êµ¬ ì‹¤í–‰ íŒ¨í„´
        tool_pattern = r'\[TOOL:\s*(\w+)\]\(([^)]*)\)'

        def execute_tool(match):
            tool_name = match.group(1)
            arg = match.group(2)
            result = self.tools.execute(tool_name, arg=arg)
            return f"\nğŸ“Œ {tool_name} ê²°ê³¼:\n{result}\n"

        response = re.sub(tool_pattern, execute_tool, response)

        # í•™ìŠµ íŒ¨í„´
        learn_pattern = r'\[LEARN:\s*(\w+)\]\(([^)]*)\)'

        def save_learning(match):
            category = match.group(1)
            content = match.group(2)
            self.memory.add_learning(category, content)
            return f"\nğŸ’¡ í•™ìŠµë¨: [{category}] {content}\n"

        response = re.sub(learn_pattern, save_learning, response)

        return response

    def build_prompt(self, user_input: str) -> str:
        """í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        # ìµœê·¼ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
        context_parts = []

        for msg in self.memory.short_term[-5:]:
            role = "User" if msg["role"] == "user" else "AI"
            context_parts.append(f"{role}: {msg['content']}")

        # ê´€ë ¨ í•™ìŠµ ë‚´ìš©
        if self.memory.learnings:
            recent_learnings = self.memory.learnings[-5:]
            learning_text = "\n".join([
                f"- [{l['category']}] {l['content']}"
                for l in recent_learnings
            ])
            context_parts.append(f"\n[í•™ìŠµëœ ì§€ì‹]\n{learning_text}")

        context = "\n".join(context_parts)

        prompt = f"""[ëŒ€í™” ê¸°ë¡]
{context}

User: {user_input}
AI:"""

        return prompt

    def chat(self, user_input: str) -> str:
        """ëŒ€í™”"""
        # ë©”ëª¨ë¦¬ì— ì¶”ê°€
        self.memory.add_conversation("user", user_input)

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self.build_prompt(user_input)

        # ì‘ë‹µ ìƒì„±
        print("\nğŸ¤– AI: ", end="", flush=True)
        response = self.ollama.generate(prompt, system=self.system_prompt)

        # ì‘ë‹µ ì²˜ë¦¬ (ë„êµ¬ ì‹¤í–‰ ë“±)
        processed = self.process_response(response)
        if processed != response:
            print(processed)

        # ë©”ëª¨ë¦¬ì— ì¶”ê°€
        self.memory.add_conversation("assistant", response)
        self.memory.save()

        return response

    def on_voice_input(self, text: str):
        """ìŒì„± ì…ë ¥ ì²˜ë¦¬"""
        self.input_queue.put(text)

    def run(self, enable_mic: bool = True):
        """ì‹¤í–‰"""
        print("\n" + "=" * 50)
        print("  ğŸ¤– ì‹¤ì‹œê°„ AI ì—ì´ì „íŠ¸")
        print("=" * 50)

        # Ollama í™•ì¸
        if not self.ollama.is_available():
            print("âŒ Ollamaê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ")
            print("   ì‹¤í–‰: ollama serve")
            return

        print(f"âœ… ëª¨ë¸: {MODEL_NAME}")
        print(f"ğŸ“š í•™ìŠµ ë‚´ìš©: {len(self.memory.learnings)}ê°œ")

        # ë§ˆì´í¬ ì²­ì·¨ ì‹œì‘
        if enable_mic:
            self.mic_listener = MicrophoneListener(self.on_voice_input)
            self.mic_listener.start()

        print("\nëª…ë ¹ì–´:")
        print("  /quit - ì¢…ë£Œ")
        print("  /learn <ë‚´ìš©> - í•™ìŠµ")
        print("  /memory - ë©”ëª¨ë¦¬ ìƒíƒœ")
        print("  /tools - ë„êµ¬ ëª©ë¡")
        print("  /mic on/off - ë§ˆì´í¬ í† ê¸€")
        print("=" * 50 + "\n")

        self.running = True

        while self.running:
            try:
                # ìŒì„± ì…ë ¥ í™•ì¸
                try:
                    voice_text = self.input_queue.get_nowait()
                    self.chat(voice_text)
                    continue
                except queue.Empty:
                    pass

                # í…ìŠ¤íŠ¸ ì…ë ¥
                user_input = input("ğŸ‘¤ You: ").strip()

                if not user_input:
                    continue

                # ëª…ë ¹ì–´ ì²˜ë¦¬
                if user_input.startswith("/"):
                    self._handle_command(user_input)
                    continue

                # ëŒ€í™”
                self.chat(user_input)

            except KeyboardInterrupt:
                print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜: {e}")

        # ì •ë¦¬
        if self.mic_listener:
            self.mic_listener.stop()
        self.memory.save()

    def _handle_command(self, cmd: str):
        """ëª…ë ¹ì–´ ì²˜ë¦¬"""
        if cmd == "/quit":
            self.running = False

        elif cmd.startswith("/learn "):
            content = cmd[7:]
            self.memory.add_learning("user_taught", content, "direct")
            print(f"ğŸ’¡ í•™ìŠµë¨: {content}")

        elif cmd == "/memory":
            print(f"\nğŸ“š ë©”ëª¨ë¦¬ ìƒíƒœ:")
            print(f"  ë‹¨ê¸° ê¸°ì–µ: {len(self.memory.short_term)}ê°œ")
            print(f"  í•™ìŠµ ë‚´ìš©: {len(self.memory.learnings)}ê°œ")
            print(f"  ì¥ê¸° ì§€ì‹: {len(self.memory.long_term)}ê°œ")

        elif cmd == "/tools":
            print("\nğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:")
            for name in self.tools.tools:
                print(f"  - {name}")

        elif cmd == "/mic on":
            if self.mic_listener:
                self.mic_listener.start()
                print("ğŸ¤ ë§ˆì´í¬ í™œì„±í™”")

        elif cmd == "/mic off":
            if self.mic_listener:
                self.mic_listener.stop()
                print("ğŸ”‡ ë§ˆì´í¬ ë¹„í™œì„±í™”")

        else:
            print("â“ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´")


def main():
    """ë©”ì¸"""
    # requests í™•ì¸
    try:
        import requests
    except ImportError:
        print("âŒ requests ë¯¸ì„¤ì¹˜")
        print("   ì„¤ì¹˜: pip3 install requests")
        return

    ai = RealtimeAI()
    ai.run(enable_mic=True)


if __name__ == "__main__":
    main()
